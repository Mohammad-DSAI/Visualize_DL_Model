{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72IYtaCxSsAM"
      },
      "outputs": [],
      "source": [
        "# example of summarizing a model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(8,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of plotting a model\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(8,)))\n",
        "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# summarize the model\n",
        "plot_model(model, 'model.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "hRsTpwpWY1zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of plotting learning curves\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from matplotlib import pyplot\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "sgd = SGD(learning_rate=0.001, momentum=0.8)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
        "# fit the model\n",
        "history = model.fit(X, y, epochs=100, batch_size=32, verbose=0, validation_split=0.3)\n",
        "# plot learning curves\n",
        "pyplot.title('Learning Curves')\n",
        "pyplot.xlabel('Epoch')\n",
        "pyplot.ylabel('Cross Entropy')\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='val')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "goOG0-vYgMaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of saving a fit model\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_classes=2, random_state=1)\n",
        "# determine the number of input features\n",
        "n_features = X.shape[1]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "sgd = SGD(learning_rate=0.001, momentum=0.8)\n",
        "model.compile(optimizer=sgd, loss='binary_crossentropy')\n",
        "# fit the model\n",
        "model.fit(X, y, epochs=100, batch_size=32, verbose=0, validation_split=0.3)\n",
        "# save model to file\n",
        "model.save('model.h5')"
      ],
      "metadata": {
        "id": "RDXqZqkThtWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example of loading a saved model\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras.models import load_model\n",
        "# create the dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=4, n_classes=2, random_state=1)\n",
        "# load the model from file\n",
        "model = load_model('model.h5')\n",
        "# make a prediction\n",
        "row = [1.91518414, 1.14995454, -1.52847073, 0.79430654]\n",
        "yhat = model.predict([row])\n",
        "print('Predicted: %.3f' % yhat[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APVW7XEuiLM7",
        "outputId": "06ba9b0d-5653-49f6-9eb9-e297b3d4fda8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 167ms/step\n",
            "Predicted: 0.858\n"
          ]
        }
      ]
    }
  ]
}